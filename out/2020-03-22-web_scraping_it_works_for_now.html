<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/61c34c770a7cdebe.css" as="style"/><link rel="stylesheet" href="/_next/static/css/61c34c770a7cdebe.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-514908bffb652963.js" defer=""></script><script src="/_next/static/chunks/framework-91d7f78b5b4003c8.js" defer=""></script><script src="/_next/static/chunks/main-66dc39025408cecd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-523827c30b7a8faf.js" defer=""></script><script src="/_next/static/chunks/404-799ed97a88104c89.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-df68f09ffa9896e5.js" defer=""></script><script src="/_next/static/4ErMHlRWo7lJTqC6JsD9E/_buildManifest.js" defer=""></script><script src="/_next/static/4ErMHlRWo7lJTqC6JsD9E/_ssgManifest.js" defer=""></script><script src="/_next/static/4ErMHlRWo7lJTqC6JsD9E/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><div class="container"><nav class="nav"><h2 href="/">BlogLolaBlog</h2><p href="/about">About Me</p></nav><main><div><h1>Web Scraping, it works... for now</h1><p>Hello, welcome to my second blog post. In this section I will be going over web scraping using nokogiri and hopefully assist people getting over the same hurdles I did when tackling this task.</p><p>So lets start off with the biggest thing there will be a lot of back and forth so when you are ready to start coding your scraper be prepared to be debugging for a while.</p><p>To get everything started you are going to want to use Nokogiri to get the information from the webpage you want to scrape from using a pretty straight forward command.</p><pre style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code class="language-ruby" style="white-space:pre"><span>
</span>        doc = Nokogiri::HTML(open(url))
<!-- -->    
</code></pre><p>Now to get this working you will need to require nokogiri and open-uri.</p><p>Awesome! now we have a webpage&#x27;s contents saved into a handy place in memory where we can work from.</p><p>From here we will be searching the information we saved to the <code>doc</code> variable. This is done by a method in Nokogiri named #css. To use this method we will be inspecting the webpage for tags and classes in the HTML. Luckily for us most developers reuse these classes for items that are similar, this is great that means we can find items that are the same to use for collections.</p><p>In my case I was after these</p><p><img src="https://i.ibb.co/F66nbHn/event.png"/></p><p>more importantly I was after the links so I could repeat the whole process again for each event page</p><p>To do this I had to search the html for useful classes and tags. I realized that the linkes were nested inside an h2 with the class name &quot;tribe-events-list-event-title&quot; hmm easy enough for now the next tag was of course an a tag since i was looking for links. At this point I knew I needed a collection of links that followed this pattern so using the map function seemed like the best bet as it returns an array of the new items working on so my line of code ended up being this</p><pre style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code class="language-ruby" style="white-space:pre"><span>
</span><span>        </span><span style="color:#BC6060">@links</span><span> = </span><span style="color:#BC6060">@doc</span><span>.css(</span><span style="color:#880000">&#x27;h2.tribe-events-list-event-title a&#x27;</span><span>).map {</span><span class="hljs-params">|link|</span><span> link[</span><span style="color:#880000">&#x27;href&#x27;</span><span>]}
</span>    
</code></pre><p>So to this point, I scraped the events page for all the links to the events and saved them to an array. Unfortunately, this was only half the work I needed to do to get my program working.</p><p>in each of these links was a page containing the name of the event, a date, and a description so I knew I needed to do this for each page so that means I need to use nokogiri to do so on each page. I decided to use an iterator to create an object for each page to make accessing all this information easier (also the project required I do that... but regardless).</p><p>Since I did not need to return anything specific and I was simply doing all my work in the block of code the simple each iterator does the job.</p><p>Just as a little background I used mass assignment in my Event class so only a hash is passed in to the method instead of a bunch of order specific arguments</p><pre style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code class="language-ruby" style="white-space:pre"><span>
</span><span>        </span><span class="hljs-function" style="font-weight:bold">def</span><span class="hljs-function"> </span><span class="hljs-function" style="color:#880000;font-weight:bold">initialize</span><span class="hljs-function hljs-params">(attributes)</span><span>
</span><span>            attributes.each {</span><span class="hljs-params">|key, value|</span><span> </span><span style="font-weight:bold">self</span><span>.send((</span><span style="color:#880000">&quot;</span><span style="color:#444">#{key}</span><span style="color:#880000">=&quot;</span><span>), value)}
</span>            save
<span>        </span><span style="font-weight:bold">end</span><span>
</span>    
</code></pre><p>Now to operate on my <code>@links</code> array</p><pre style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code class="language-ruby" style="white-space:pre"><span>
</span><span>        </span><span style="color:#BC6060">@links</span><span>.each </span><span style="font-weight:bold">do</span><span> </span><span class="hljs-params">|link|</span><span>
</span>            event_page = Nokogiri::HTML(open(link))
<span>            </span><span style="color:#888888">#:name, :date, :description</span><span>
</span>            attributes = {}
<span>            attributes[</span><span style="color:#BC6060">:name</span><span>] = event_page.css(</span><span style="color:#880000">&quot;h1.tribe-events-single-event-title&quot;</span><span>).text
</span><span>            attributes[</span><span style="color:#BC6060">:date</span><span>] = event_page.css(</span><span style="color:#880000">&quot;h2 span.tribe-event-date-start&quot;</span><span>).text
</span><span>            attributes[</span><span style="color:#BC6060">:description</span><span>] = event_page.css(</span><span style="color:#880000">&quot;div.tribe-events-single-event-description p&quot;</span><span>).first.text
</span>            e = Event.new(attributes)
<span>            </span><span style="color:#BC6060">@calendar</span><span>.events = e
</span><span>        </span><span style="font-weight:bold">end</span><span>
</span>    
</code></pre><p>It may seem like a lot is going on here but its really simple once you read through it really the worst part is combing through the web inspector in chrome to find the arguments for nokogiri</p><p>Now, what this method does is create a new doc like we did to get the links using Nokogiri. Once its parse it saves the information from the specified areas to a key in a new hash named attributes, then it creates a new Event instance passing in the new hash and then adds it to the calendars events instance variable using an overwritten events= method</p><pre style="display:block;overflow-x:auto;padding:0.5em;background:#F0F0F0;color:#444"><code class="language-ruby" style="white-space:pre"><span>
</span><span>        </span><span class="hljs-function" style="font-weight:bold">def</span><span class="hljs-function"> </span><span class="hljs-function" style="color:#880000;font-weight:bold">events=</span><span class="hljs-function hljs-params">(event)</span><span>
</span><span>            </span><span style="font-weight:bold">if</span><span> event.is_a?(Event)
</span><span>                </span><span style="color:#BC6060">@events</span><span> &lt;&lt; event
</span><span>            </span><span style="font-weight:bold">end</span><span>
</span><span>        </span><span style="font-weight:bold">end</span><span>
</span>    
</code></pre><p>This checks to make sure the passed in argument is indeed an instance of Event and adds it to an array for easy management.</p><p>So at this point everything is working fine and the program scrapes the information and displays it as it should but then comes the caveat of web scraping.... It&#x27;s not a static website meaning when they change their website for any reason it has the potential of breaking my program. While it works now... there is no guaranteed longevity to my program. Luckily this is just a portfolio project to demonstrate object relationships and web scraping techniques as the fragility of wweb scraping definitly makes me uncomfortable and would deter me from using it for an end user application.</p><p>So in conclusion... It works! for now...</p></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontMatter":{"title":"Web Scraping, it works... for now","date":"Mar 22nd, 2020","description":"Web scraping with nokogiri and Ruby","tags":["functions","javascript"]},"slug":"2020-03-22-web_scraping_it_works_for_now","mdxSource":{"compiledSource":"var p=Object.defineProperty,g=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var h=(e,t,n)=\u003et in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,i=(e,t)=\u003e{for(var n in t||(t={}))s.call(t,n)\u0026\u0026h(e,n,t[n]);if(o)for(var n of o(t))r.call(t,n)\u0026\u0026h(e,n,t[n]);return e},l=(e,t)=\u003eg(e,c(t));var d=(e,t)=\u003e{var n={};for(var a in e)s.call(e,a)\u0026\u0026t.indexOf(a)\u003c0\u0026\u0026(n[a]=e[a]);if(e!=null\u0026\u0026o)for(var a of o(e))t.indexOf(a)\u003c0\u0026\u0026r.call(e,a)\u0026\u0026(n[a]=e[a]);return n};const makeShortcode=e=\u003efunction(n){return console.warn(\"Component \"+e+\" was not imported, exported, or provided by MDXProvider as global scope\"),mdx(\"div\",i({},n))},SyntaxHighlighter=makeShortcode(\"SyntaxHighlighter\"),layoutProps={},MDXLayout=\"wrapper\";function MDXContent(n){var a=n,{components:e}=a,t=d(a,[\"components\"]);return mdx(MDXLayout,l(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Hello, welcome to my second blog post. In this section I will be going over web scraping using nokogiri and hopefully assist people getting over the same hurdles I did when tackling this task.\"),mdx(\"p\",null,\"So lets start off with the biggest thing there will be a lot of back and forth so when you are ready to start coding your scraper be prepared to be debugging for a while.\"),mdx(\"p\",null,\"To get everything started you are going to want to use Nokogiri to get the information from the webpage you want to scrape from using a pretty straight forward command.\"),mdx(SyntaxHighlighter,{language:\"ruby\",mdxType:\"SyntaxHighlighter\"},`\n        doc = Nokogiri::HTML(open(url))\n    `),mdx(\"p\",null,\"Now to get this working you will need to require nokogiri and open-uri.\"),mdx(\"p\",null,\"Awesome! now we have a webpage's contents saved into a handy place in memory where we can work from.\"),mdx(\"p\",null,\"From here we will be searching the information we saved to the \",mdx(\"inlineCode\",{parentName:\"p\"},\"doc\"),\" variable. This is done by a method in Nokogiri named #css. To use this method we will be inspecting the webpage for tags and classes in the HTML. Luckily for us most developers reuse these classes for items that are similar, this is great that means we can find items that are the same to use for collections.\"),mdx(\"p\",null,\"In my case I was after these\"),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"https://i.ibb.co/F66nbHn/event.png\",alt:null}))),mdx(\"p\",null,\"more importantly I was after the links so I could repeat the whole process again for each event page\"),mdx(\"p\",null,'To do this I had to search the html for useful classes and tags. I realized that the linkes were nested inside an h2 with the class name \"tribe-events-list-event-title\" hmm easy enough for now the next tag was of course an a tag since i was looking for links. At this point I knew I needed a collection of links that followed this pattern so using the map function seemed like the best bet as it returns an array of the new items working on so my line of code ended up being this'),mdx(SyntaxHighlighter,{language:\"ruby\",mdxType:\"SyntaxHighlighter\"},`\n        @links = @doc.css('h2.tribe-events-list-event-title a').map {|link| link['href']}\n    `),mdx(\"p\",null,\"So to this point, I scraped the events page for all the links to the events and saved them to an array. Unfortunately, this was only half the work I needed to do to get my program working.\"),mdx(\"p\",null,\"in each of these links was a page containing the name of the event, a date, and a description so I knew I needed to do this for each page so that means I need to use nokogiri to do so on each page. I decided to use an iterator to create an object for each page to make accessing all this information easier (also the project required I do that... but regardless).\"),mdx(\"p\",null,\"Since I did not need to return anything specific and I was simply doing all my work in the block of code the simple each iterator does the job.\"),mdx(\"p\",null,\"Just as a little background I used mass assignment in my Event class so only a hash is passed in to the method instead of a bunch of order specific arguments\"),mdx(SyntaxHighlighter,{language:\"ruby\",mdxType:\"SyntaxHighlighter\"},`\n        def initialize(attributes)\n            attributes.each {|key, value| self.send((\"#{key}=\"), value)}\n            save\n        end\n    `),mdx(\"p\",null,\"Now to operate on my \",mdx(\"inlineCode\",{parentName:\"p\"},\"@links\"),\" array\"),mdx(SyntaxHighlighter,{language:\"ruby\",mdxType:\"SyntaxHighlighter\"},`\n        @links.each do |link|\n            event_page = Nokogiri::HTML(open(link))\n            #:name, :date, :description\n            attributes = {}\n            attributes[:name] = event_page.css(\"h1.tribe-events-single-event-title\").text\n            attributes[:date] = event_page.css(\"h2 span.tribe-event-date-start\").text\n            attributes[:description] = event_page.css(\"div.tribe-events-single-event-description p\").first.text\n            e = Event.new(attributes)\n            @calendar.events = e\n        end\n    `),mdx(\"p\",null,\"It may seem like a lot is going on here but its really simple once you read through it really the worst part is combing through the web inspector in chrome to find the arguments for nokogiri\"),mdx(\"p\",null,\"Now, what this method does is create a new doc like we did to get the links using Nokogiri. Once its parse it saves the information from the specified areas to a key in a new hash named attributes, then it creates a new Event instance passing in the new hash and then adds it to the calendars events instance variable using an overwritten events= method\"),mdx(SyntaxHighlighter,{language:\"ruby\",mdxType:\"SyntaxHighlighter\"},`\n        def events=(event)\n            if event.is_a?(Event)\n                @events \u003c\u003c event\n            end\n        end\n    `),mdx(\"p\",null,\"This checks to make sure the passed in argument is indeed an instance of Event and adds it to an array for easy management.\"),mdx(\"p\",null,\"So at this point everything is working fine and the program scrapes the information and displays it as it should but then comes the caveat of web scraping.... It's not a static website meaning when they change their website for any reason it has the potential of breaking my program. While it works now... there is no guaranteed longevity to my program. Luckily this is just a portfolio project to demonstrate object relationships and web scraping techniques as the fragility of wweb scraping definitly makes me uncomfortable and would deter me from using it for an end user application.\"),mdx(\"p\",null,\"So in conclusion... It works! for now...\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},"__N_SSG":true},"page":"/[slug]","query":{"slug":"2020-03-22-web_scraping_it_works_for_now"},"buildId":"4ErMHlRWo7lJTqC6JsD9E","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>